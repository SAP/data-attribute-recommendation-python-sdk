{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOcC_6DPKpfT"
      },
      "source": [
        "# Data Attribute Recommendation - Generic Model Template\n",
        "\n",
        "Deep dive into the Python SDK for the Data Attribute Recommendation service to explore when and how to use the generic model template."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOZtajh3KpfY"
      },
      "source": [
        "## Business Scenario\n",
        "\n",
        "We will consider a business scenario involving product master data. The creation and maintenance of this product master data requires the careful manual selection of the correct categories for a given product from a pre-defined label of product categories.\n",
        "\n",
        "In this workshop, we will explore how to automate this tedious manual task with the Data Attribute Recommendation service."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CA3glKpPKpfZ"
      },
      "source": [
        "This workshop will cover:\n",
        "    \n",
        "* Data Upload\n",
        "* Model Training and Deployment\n",
        "* Inference Requests\n",
        "    \n",
        "We will work through a basic example of how to achieve these tasks using the [Python SDK for Data Attribute Recommendation](https://github.com/SAP/data-attribute-recommendation-python-sdk).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgIt1MKkKpfa"
      },
      "source": [
        "*Note: if you are doing several runs of this notebook on a trial account, you may see errors stating 'The resource can no longer be used. Usage limit has been reached'. It can be beneficial to [clean up the service instance](#Cleaning-up-a-service-instance) to free up limited trial resources acquired by an earlier run of the notebook. [Some limits](https://help.sap.com/viewer/105bcfd88921418e8c29b24a7a402ec3/SHIP/en-US/c03b561eea1744c9b9892b416037b99a.html) cannot be reset this way.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OV_3oPOKpfa"
      },
      "source": [
        "## Table of Contents\n",
        "\n",
        "* [Exercise 01.1](#Exercise-01.1) - Installing the SDK and preparing the service key\n",
        "* [Exercise 01.2](#Exercise-01.2) - Uploading the data\n",
        "* [Exercise 01.3](#Exercise-01.3) - Training the model\n",
        "* [Exercise 01.4](#Exercise-01.4) - Deploying the Model and predicting labels\n",
        "* [Resources](#Resources) - Additional reading\n",
        "* [Cleaning up a service instance](#Cleaning-up-a-service-instance) - Clean up all resources on the service instance\n",
        "* [Optional Exercises](#Optional-Exercises) - Optional exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kq23_uoRKpfb"
      },
      "source": [
        "# Exercise 01.1\n",
        "\n",
        "*Back to [table of contents](#Table-of-Contents)*\n",
        "\n",
        "In exercise 01.1, we will install the SDK and prepare the service key."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXuu5qXrKpfb"
      },
      "source": [
        "## Installing the SDK"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoJNxXJmKpfb"
      },
      "source": [
        "The Data Attribute Recommendation SDK is available from the Python package repository. It can be installed with the standard `pip` tool:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bgMUF07iKpfc"
      },
      "outputs": [],
      "source": [
        "! pip install data-attribute-recommendation-sdk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bKTOWD8Kpfd"
      },
      "source": [
        "*Note: If you are not using a Jupyter notebook, but instead a regular Python development environment, we recommend using a Python virtual environment to set up your development environment. Please see [the dedicated tutorial to learn how to install the SDK inside a Python virtual environment](https://developers.sap.com/tutorials/cp-aibus-dar-sdk-setup.html).*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1a36dcPKpfd"
      },
      "source": [
        "## Creating a service instance and key on BTP Trial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1dPKyTQKpfd"
      },
      "source": [
        "Please log in to your trial account: https://cockpit.eu10.hana.ondemand.com/trial/\n",
        "\n",
        "In the your global account screen, go to the \"Boosters\" tab:\n",
        "\n",
        "![trial_booster.png](images/trial_booster.png)\n",
        "\n",
        "*Boosters are only available on the Trial landscape. If you are using a production environment, please follow this tutorial to manually [create a service instance and a service key](https://developers.sap.com/tutorials/cp-aibus-dar-service-instance.html)*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjQ0_esrKpfd"
      },
      "source": [
        "In the Boosters tab, enter \"Data Attribute Recommendation\" into the search box. Then, select the\n",
        "service tile from the search results: \n",
        "    \n",
        "![trial_locate_dar_booster.png](images/trial_locate_dar_booster.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yGm9c4dKpfe"
      },
      "source": [
        "The resulting screen shows details of the booster pack. Here, click the \"Start\" button and wait a few seconds.\n",
        "\n",
        "![trial_start_booster.png](images/trial_start_booster.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rL_rFntKpfe"
      },
      "source": [
        "Once the booster is finished, click the \"go to Service Key\" link to obtain your service key.\n",
        "\n",
        "![trial_booster_finished.png](images/trial_booster_finished.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOMd19zhKpfe"
      },
      "source": [
        "Finally, download the key and save it to disk.\n",
        "\n",
        "![trial_download_key.png](images/trial_download_key.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkk5nSzYKpff"
      },
      "source": [
        "## Loading the service key into your Jupyter Notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gjYa-qnKpff"
      },
      "source": [
        "Once you downloaded the service key from the Cockpit, upload it to your notebook environment. The service key must be uploaded to same directory where the `Data_Attribute_Recommendation_*_Model_Template.ipynb` file is stored.\n",
        "\n",
        "When using Jupyterlab, a file browser is visible to the left of the notebook view. Click the upload button here to upload the `default_key.json` file we downloaded earlier from the BTP Cockpit.\n",
        "\n",
        "\n",
        "![jupyterlab_upload_button.png](images/service_key_main_jupyter_page.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Once you click the upload button, a file chooser dialog will open where you can select the `default_key.json`:\n",
        "After the upload finished successfully, you should see the `default_key.json` in the file browser.\n",
        "**Make sure that the file name is `default_key.json`. If your service key file has a different name, this notebook will not work.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rQ3Hs4hKpff"
      },
      "source": [
        "The service key contains your credentials to access the service. Please treat this as carefully as you would treat any password. We keep the service key as a separate file outside this notebook to avoid leaking the secret credentials.\n",
        "\n",
        "The service key is a JSON file. We will load this file once and use the credentials throughout this workshop. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1qBicprdKpff"
      },
      "outputs": [],
      "source": [
        "# First, set up logging so we can see the actions performed by the SDK behind the scenes\n",
        "import logging\n",
        "import sys\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, stream=sys.stdout)\n",
        "\n",
        "from pprint import pprint # for nicer output formatting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gviGGPOwKpfg"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "if not os.path.exists(\"default_key.json\"):\n",
        "    msg = \"'default_key.json' is not found. Please follow instructions above to create a service key of\"\n",
        "    msg += \" Data Attribute Recommendation. Then, upload it into the same directory where\"\n",
        "    msg += \" this notebook is saved.\"\n",
        "    print(msg)\n",
        "    raise ValueError(msg)\n",
        "\n",
        "with open(\"default_key.json\") as file_handle:\n",
        "    key = file_handle.read()\n",
        "    SERVICE_KEY = json.loads(key)\n",
        "    print(\"Service URL: \")\n",
        "    pprint(SERVICE_KEY[\"url\"])\n",
        "    print(\"Client ID:\")\n",
        "    pprint(SERVICE_KEY[\"uaa\"][\"clientid\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXPp8AH2Kpfh"
      },
      "source": [
        "## Summary Exercise 01.1\n",
        "\n",
        "In exercise 01.1, we have covered the following topics:\n",
        "\n",
        "* How to install the Python SDK for Data Attribute Recommendation\n",
        "* How to obtain a service key for the Data Attribute Recommendation service"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76FGoj9NKpfh"
      },
      "source": [
        "# Exercise 01.2\n",
        "\n",
        "*Back to [table of contents](#Table-of-Contents)*\n",
        "*To perform this exercise, you need to execute the code in all previous exercises.*\n",
        "\n",
        "In exercise 01.2, we will upload our demo dataset to the service."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDAnHz8MKpfh"
      },
      "source": [
        "## The Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UQSlT9FKpfi"
      },
      "source": [
        "### Obtaining the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ra-0GlrFKpfi"
      },
      "source": [
        "The dataset we use in this workshop is a CSV file containing scientific paper titles and their topic categories. This dataset is ideal to understand use cases where the labels are independent of one another. What this means is that the presence or absence of one label does not influence the others."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vB624W5CKpfi"
      },
      "source": [
        "Let's inspect the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aAZHWO12Kpfi"
      },
      "outputs": [],
      "source": [
        "# if you are experiencing an import error here, run the following in a new cell:\n",
        "# ! pip install pandas\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"data/arxiv.csv\")\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gsGWY86dKpfj"
      },
      "outputs": [],
      "source": [
        "df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C9BCvD4QKpfj"
      },
      "outputs": [],
      "source": [
        "print()\n",
        "print(f\"Data has {df.shape[0]} rows and {df.shape[1]} columns.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkhVAKrWKpfk"
      },
      "source": [
        "The CSV contains the titles of several scientific papers. For each title, the set of topics associated with the title are provided as labels. The following are the labels and their associated full forms.\n",
        "- CSC: Computer Science\n",
        "- STA: Statistics\n",
        "- QFI: Quantitative Finance\n",
        "- QBI: Quantitative Biology\n",
        "- PHY: Physics\n",
        "\n",
        "For e.g., the first instance of the data `Contemporary machine learning: a guide for practitioners in the physical sciences` has the following set of labels:\n",
        "- Computer Science\n",
        "- Physics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYSS1uPaKpfk"
      },
      "source": [
        "We will use the Data Attribute Recommendation service to predict the labels for a given paper based on its **title**. However, you can add other attributes such as length of the paper, number of words, conference name and type to improve the ability to make the classifier be able to learn better."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "menoFEziKpfl"
      },
      "source": [
        "### Creating the DatasetSchema"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RU2yv8PiKpfl"
      },
      "source": [
        "We first have to describe the shape of our data by creating a DatasetSchema. This schema informs the service about the individual column types found in the CSV. We also describe which are the target columns used for training. These columns will be later predicted.\n",
        "\n",
        "The service currently supports three column types: **TEXT**, **CATEGORY** and **NUMBER**. As labels to be predicted, only **CATEGORY** and **NUMBER** is currently supported.\n",
        "\n",
        "A DatasetSchema for the Arxiv dataset looks as follows:\n",
        "\n",
        "```json\n",
        "{\n",
        "    \"features\": [\n",
        "        {\"label\": \"title\", \"type\": \"TEXT\"},\n",
        "    ],\n",
        "    \"labels\": [\n",
        "        {\"label\": \"label1\", \"type\": \"CATEGORY\"},\n",
        "        {\"label\": \"label2\", \"type\": \"CATEGORY\"},\n",
        "        {\"label\": \"label3\", \"type\": \"CATEGORY\"},\n",
        "        {\"label\": \"label4\", \"type\": \"CATEGORY\"},\n",
        "        {\"label\": \"label5\", \"type\": \"CATEGORY\"}\n",
        "    ],\n",
        "    \"name\": \"arxiv-multilabel-prediction\",\n",
        "}\n",
        "```\n",
        "\n",
        "We will now upload this DatasetSchema to the Data Attribute Recommendation service. The SDK provides the\n",
        "[`DataManagerClient.create_dataset_schema()`](https://data-attribute-recommendation-python-sdk.readthedocs.io/en/latest/api.html#sap.aibus.dar.client.data_manager_client.DataManagerClient.create_dataset_schema) method for this purpose.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oMNvoxGlKpfl"
      },
      "outputs": [],
      "source": [
        "from sap.aibus.dar.client.data_manager_client import DataManagerClient\n",
        "\n",
        "dataset_schema = {\n",
        "    \"features\": [\n",
        "        {\"label\": \"title\", \"type\": \"TEXT\"},\n",
        "    ],\n",
        "    \"labels\": [\n",
        "        {\"label\": \"label1\", \"type\": \"CATEGORY\"},\n",
        "        {\"label\": \"label2\", \"type\": \"CATEGORY\"},\n",
        "        {\"label\": \"label3\", \"type\": \"CATEGORY\"},\n",
        "        {\"label\": \"label4\", \"type\": \"CATEGORY\"},\n",
        "        {\"label\": \"label5\", \"type\": \"CATEGORY\"}\n",
        "    ],\n",
        "    \"name\": \"arxiv-multilabel-prediction\",\n",
        "}\n",
        "\n",
        "\n",
        "data_manager = DataManagerClient.construct_from_service_key(SERVICE_KEY)\n",
        "response = data_manager.create_dataset_schema(dataset_schema)\n",
        "dataset_schema_id = response[\"id\"]\n",
        "\n",
        "print()\n",
        "print(\"DatasetSchema created:\")\n",
        "\n",
        "pprint(response)\n",
        "\n",
        "print()\n",
        "print(f\"DatasetSchema ID: {dataset_schema_id}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compress file first for a faster upload\n",
        "! gzip -9 -c data/arxiv.csv > arxiv.csv.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiaMRudxKpfl"
      },
      "source": [
        "The API responds with the newly created DatasetSchema resource. The service assigned an ID to the schema. We save this ID in a variable, as we will need it when we upload the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ub8gs4KaKpfl"
      },
      "source": [
        "### Uploading the Data to the service"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poGMX3K4Kpfm"
      },
      "source": [
        "The [`DataManagerClient`](https://data-attribute-recommendation-python-sdk.readthedocs.io/en/latest/api.html#sap.aibus.dar.client.data_manager_client.DataManagerClient) class is also responsible for uploading data to the service. This data must fit to an existing DatasetSchema. After uploading the data, the service will validate the Dataset against the DatasetSchema in a background process. The data must be a CSV file which can optionally be `gzip` compressed.\n",
        "\n",
        "We will now upload our `arxiv.csv.gz` file, using the DatasetSchema which we created earlier.\n",
        "\n",
        "Data upload is a two-step process. We first create the Dataset using [`DataManagerClient.create_dataset()`](https://data-attribute-recommendation-python-sdk.readthedocs.io/en/latest/api.html#sap.aibus.dar.client.data_manager_client.DataManagerClient.create_dataset). Then we can upload data to the Dataset using the [`DataManagerClient.upload_data_to_dataset()`](https://data-attribute-recommendation-python-sdk.readthedocs.io/en/latest/api.html#sap.aibus.dar.client.data_manager_client.DataManagerClient.upload_data_to_dataset) method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AGVvXs0ZKpfm"
      },
      "outputs": [],
      "source": [
        "dataset_resource = data_manager.create_dataset(\"arxiv-category-dataset\", dataset_schema_id)\n",
        "dataset_id = dataset_resource[\"id\"]\n",
        "\n",
        "print()\n",
        "print(\"Dataset created:\")\n",
        "\n",
        "pprint(dataset_resource)\n",
        "\n",
        "print()\n",
        "print(f\"Dataset ID: {dataset_id}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXmWC9JNKpfm"
      },
      "source": [
        "Note that the data upload can take a few minutes. Please do not restart the process while the cell is still running."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vSOL8PxfKpfm"
      },
      "outputs": [],
      "source": [
        "# Open in binary mode.\n",
        "with open('arxiv.csv.gz', 'rb') as file_handle:\n",
        "    dataset_resource = data_manager.upload_data_to_dataset(dataset_id, file_handle)\n",
        "\n",
        "print()\n",
        "print(\"Dataset after data upload:\")\n",
        "print()\n",
        "pprint(dataset_resource)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DOYjZDlKpfm"
      },
      "source": [
        "Note that the Dataset status changed from `NO_DATA` to `VALIDATING`.\n",
        "\n",
        "Dataset validation is a background process. The status will eventually change from `VALIDATING` to `SUCCEEDED`.\n",
        "The SDK provides the [`DataManagerClient.wait_for_dataset_validation()`](https://data-attribute-recommendation-python-sdk.readthedocs.io/en/latest/api.html#sap.aibus.dar.client.data_manager_client.DataManagerClient.wait_for_dataset_validation) method to poll for the Dataset validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xs4pYGYVKpfm"
      },
      "outputs": [],
      "source": [
        "dataset_resource = data_manager.wait_for_dataset_validation(dataset_id)\n",
        "\n",
        "print()\n",
        "print(\"Dataset after validation has finished:\")\n",
        "\n",
        "print()\n",
        "pprint(dataset_resource)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAWb30mMKpfn"
      },
      "source": [
        "If the status is `FAILED` instead of `SUCCEEDED`, then the `validationMessage` will contain details about the validation failure."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vwjzd59Kpfn"
      },
      "source": [
        "## Summary Exercise 01.2\n",
        "\n",
        "In exercise 01.2, we have covered the following topics:\n",
        "\n",
        "* How to create a DatasetSchema\n",
        "* How to upload a Dataset to the service\n",
        "\n",
        "You can find optional exercises related to exercise 01.2 [below](#Optional-Exercises-for-01.2)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsLxijzpKpfn"
      },
      "source": [
        "# Exercise 01.3\n",
        "\n",
        "*Back to [table of contents](#Table-of-Contents)*\n",
        "\n",
        "*To perform this exercise, you need to execute the code in all previous exercises.*\n",
        "\n",
        "In exercise 01.3, we will train the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWyZIjzLKpfn"
      },
      "source": [
        "## Training the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5uM-SIFKpfo"
      },
      "source": [
        "The Dataset is now uploaded and has been validated successfully by the service.\n",
        "\n",
        "To train a machine learning model, we first need to select the correct model template."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5Lt67cuKpfo"
      },
      "source": [
        "### Selecting the right ModelTemplate\n",
        "\n",
        "The Data Attribute Recommendation service currently supports the following ModelTemplates:\n",
        "\n",
        "| ID                                   | Name                  | Description                                                               |\n",
        "|--------------------------------------|---------------------------|---------------------------------------------------------------------------|\n",
        "| d7810207-ca31-4d4d-9b5a-841a644fd81f | **Hierarchical template** | Recommended for the prediction of multiple classes that form a hierarchy. |\n",
        "| 223abe0f-3b52-446f-9273-f3ca39619d2c | **Generic template**      | Generic neural network for multi-label, multi-class classification.       |\n",
        "| 188df8b2-795a-48c1-8297-37f37b25ea00 | **AutoML template**      | Finds the best machine learning model out of several traditional algorithms. Single output only. ([Blog post](https://blogs.sap.com/2021/04/28/how-does-automl-works-in-data-attribute-recommendation/)) |\n",
        "| bdbcd699-4419-40a5-abb8-e7ad43dde49b | **Regression template**      | Predict the numeric value of a field. Single output only. ([Blog post](https://blogs.sap.com/2021/11/14/solving-regression-use-cases-with-data-attribute-recommendation/)) |\n",
        "\n",
        "\n",
        "We are building a model to predict the labels which are independent of one another. The **Generic template** is correct for this scenario. \n",
        "\n",
        "Refer to the [official documentation on ModelTemplates](https://help.sap.com/viewer/105bcfd88921418e8c29b24a7a402ec3/SHIP/en-US/1e76e8c636974a06967552c05d40e066.html) to learn more. Additional model templates may be added over time, so check back regularly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6F0ko2U9Kpfo"
      },
      "source": [
        "## Starting the training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgjV1v6xKpfp"
      },
      "source": [
        "When working with models, we use the [`ModelManagerClient`](https://data-attribute-recommendation-python-sdk.readthedocs.io/en/latest/api.html#sap.aibus.dar.client.model_manager_client.ModelManagerClient) class.\n",
        "\n",
        "To start the training, we need the IDs of the dataset and the desired model template. We also have to provide a name for the model.\n",
        "The [`ModelManagerClient.create_job()`](https://data-attribute-recommendation-python-sdk.readthedocs.io/en/latest/api.html#sap.aibus.dar.client.model_manager_client.ModelManagerClient.create_job) method launches the training Job.\n",
        "\n",
        "*Only one model of a given name can exist. If you receive a message stating 'The model name specified is already in use', you either have to remove the model and its associated model first or you have to change the `model_name` variable name below. You can also [clean up the entire service instance](#Cleaning-up-a-service-instance).*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3M-Nb9rKpfp",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "from sap.aibus.dar.client.model_manager_client import ModelManagerClient\n",
        "from sap.aibus.dar.client.exceptions import DARHTTPException\n",
        "\n",
        "model_manager = ModelManagerClient.construct_from_service_key(SERVICE_KEY)\n",
        "\n",
        "model_template_id = \"223abe0f-3b52-446f-9273-f3ca39619d2c\" # multi-label template\n",
        "model_name = \"arxiv-multilabel-model\"\n",
        "\n",
        "job_resource = model_manager.create_job(model_name, dataset_id, model_template_id)\n",
        "job_id = job_resource['id']\n",
        "\n",
        "print()\n",
        "print(\"Job resource:\")\n",
        "print()\n",
        "\n",
        "pprint(job_resource)\n",
        "\n",
        "print()\n",
        "print(f\"ID of submitted Job: {job_id}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65MsOPixKpfp"
      },
      "source": [
        "The job is now running in the background. Similar to the DatasetValidation, we have to poll the job until it succeeds.\n",
        "The SDK provides the [`ModelManagerClient.wait_for_job()`](https://data-attribute-recommendation-python-sdk.readthedocs.io/en/latest/api.html#sap.aibus.dar.client.model_manager_client.ModelManagerClient.wait_for_job) method:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o9wwVAghKpfp"
      },
      "outputs": [],
      "source": [
        "job_resource = model_manager.wait_for_job(job_id)\n",
        "\n",
        "print()\n",
        "\n",
        "print(\"Job resource after training is finished:\")\n",
        "\n",
        "pprint(job_resource)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzU3blu7Kpfq"
      },
      "source": [
        "## Intermission\n",
        "\n",
        "The model training will take between 5 and 10 minutes.\n",
        "\n",
        "In the meantime, we can explore the available [resources](#Resources) for both the service and the SDK."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWRvcnAVKpfq"
      },
      "source": [
        "## Inspecting the Model\n",
        "\n",
        "Once the training job is finished successfully, we can inspect the model using [`ModelManagerClient.read_model_by_name()`](https://data-attribute-recommendation-python-sdk.readthedocs.io/en/latest/api.html#sap.aibus.dar.client.model_manager_client.ModelManagerClient.read_model_by_name).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GreEKhzhKpfq"
      },
      "outputs": [],
      "source": [
        "model_resource = model_manager.read_model_by_name(model_name)\n",
        "\n",
        "print()\n",
        "pprint(model_resource)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFowJ79OKpfq"
      },
      "source": [
        "In the model resource, the `validationResult` key provides information about model performance. You can also use these metrics to compare performance of different [ModelTemplates](#Selecting-the-right-ModelTemplate) or different datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_nTqMTBKpfq"
      },
      "source": [
        "## Summary Exercise 01.3\n",
        "\n",
        "In exercise 01.3, we have covered the following topics:\n",
        "\n",
        "* How to select the appropriate ModelTemplate\n",
        "* How to train a Model from a previously uploaded Dataset\n",
        "\n",
        "You can find optional exercises related to exercise 01.3 [below](#Optional-Exercises-for-01.3)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQOhLJtlKpfq"
      },
      "source": [
        "# Exercise 01.4\n",
        "\n",
        "*Back to [table of contents](#Table-of-Contents)*\n",
        "\n",
        "*To perform this exercise, you need to execute the code in all previous exercises.*\n",
        "\n",
        "In exercise 01.4, we will deploy the model and predict labels for some unlabeled data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NT2YyY-5Kpfq"
      },
      "source": [
        "## Deploying the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W09I3I7vKpfr"
      },
      "source": [
        "The training job has finished and the model is ready to be deployed. By deploying the model, we create a server process in the background on the Data Attribute Recommendation service which will serve inference requests.\n",
        "\n",
        "In the SDK, the [`ModelManagerClient.create_deployment()`](https://data-attribute-recommendation-python-sdk.readthedocs.io/en/latest/api.html#module-sap.aibus.dar.client.model_manager_client) method lets us create a Deployment.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55ChYG38Kpfr"
      },
      "outputs": [],
      "source": [
        "deployment_resource =  model_manager.create_deployment(model_name)\n",
        "deployment_id = deployment_resource[\"id\"]\n",
        "\n",
        "print()\n",
        "print(\"Deployment resource:\")\n",
        "print()\n",
        "\n",
        "pprint(deployment_resource)\n",
        "\n",
        "print(f\"Deployment ID: {deployment_id}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RnditlOKpfr"
      },
      "source": [
        "*Note: if you are using a trial account and you see errors such as 'The resource can no longer be used. Usage limit has been reached', consider [cleaning up the service instance](#Cleaning-up-a-service-instance) to free up limited trial resources.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9T3cMaxKpfr"
      },
      "source": [
        "Similar to the data upload and the training job, model deployment is an asynchronous process. We have to poll the API until the Deployment is in status `SUCCEEDED`. The SDK provides the [`ModelManagerClient.wait_for_deployment()`](https://data-attribute-recommendation-python-sdk.readthedocs.io/en/latest/api.html#sap.aibus.dar.client.model_manager_client.ModelManagerClient.wait_for_deployment) for this purposes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OVntcMdyKpfr"
      },
      "outputs": [],
      "source": [
        "deployment_resource = model_manager.wait_for_deployment(deployment_id)\n",
        "\n",
        "print()\n",
        "print(\"Finished deployment resource:\")\n",
        "print()\n",
        "\n",
        "pprint(deployment_resource)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJEGMTKvKpfs"
      },
      "source": [
        "Once the Deployment is in status `SUCCEEDED`, we can run inference requests."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emtXXM24Kpfs"
      },
      "source": [
        "*For trial users: the deployment will be stopped after 8 hours. You can restart it by deleting the deployment and creating a new one for your model. The [`ModelManagerClient.ensure_deployment_exists()`](https://help.sap.com/viewer/105bcfd88921418e8c29b24a7a402ec3/SHIP/en-US/c03b561eea1744c9b9892b416037b99a.html) method will delete and re-create automatically. Then, you need to poll until the deployment is succeeded using [`ModelManagerClient.wait_for_deployment()`](https://data-attribute-recommendation-python-sdk.readthedocs.io/en/latest/api.html#sap.aibus.dar.client.model_manager_client.ModelManagerClient.wait_for_deployment) as above.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFZqPeRQKpfs"
      },
      "source": [
        "## Executing Inference requests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzMRqNtNKpfs"
      },
      "source": [
        "With a single inference request, we can send up to 50 objects to the service to predict the labels. The data send to the service must match the `features` section of the DatasetSchema created earlier. The `labels` defined inside of the DatasetSchema will be predicted for each object and returned as a response to the request.\n",
        "\n",
        "In the SDK, the [`InferenceClient.create_inference_request()`](https://data-attribute-recommendation-python-sdk.readthedocs.io/en/latest/api.html#sap.aibus.dar.client.inference_client.InferenceClient.create_inference_request) method handles submission of inference requests."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "euvXTlwAKpfs"
      },
      "outputs": [],
      "source": [
        "from sap.aibus.dar.client.inference_client import InferenceClient\n",
        "\n",
        "inference = InferenceClient.construct_from_service_key(SERVICE_KEY)\n",
        "\n",
        "objects_to_be_classified = [\n",
        "    {\n",
        "        \"features\": [\n",
        "            {\"name\": \"title\", \"value\": \"Not even wrong: The spurious link between biodiversity and ecosystem functioning\"}\n",
        "        ],\n",
        "    },\n",
        "]\n",
        "\n",
        "inference_response = inference.create_inference_request(model_name, objects_to_be_classified)\n",
        "\n",
        "print()\n",
        "print(\"Inference request processed. Response:\")\n",
        "print()\n",
        "pprint(inference_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyoPoo3PKpfs"
      },
      "source": [
        "*Note: For trial accounts, you only have a limited number of objects which you can classify.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEB-eFhwKpfs"
      },
      "source": [
        "You can also try to come up with your own example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uj4icPfGKpft"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "my_own_items = [\n",
        "    {\n",
        "        \"features\": [\n",
        "            {\"name\": \"title\", \"value\": \"EDIT THIS\"}        \n",
        "        ],\n",
        "    },\n",
        "]\n",
        "\n",
        "inference_response = inference.create_inference_request(model_name, my_own_items)\n",
        "\n",
        "print()\n",
        "print(\"Inference request processed. Response:\")\n",
        "print()\n",
        "pprint(inference_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyDkoOz3Kpft"
      },
      "source": [
        "You can also classify multiple objects at once. For each object, the `top_n` parameter determines how many predictions are returned."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HocHMqulKpft"
      },
      "outputs": [],
      "source": [
        "objects_to_be_classified = [\n",
        "    {\n",
        "        \"objectId\": \"optional-identifier-1\",\n",
        "        \"features\": [\n",
        "            {\"name\": \"title\", \"value\": \"Low-luminosity stellar wind accretion onto neutron stars in HMXBs\"}        \n",
        "        ],\n",
        "    },\n",
        "    {\n",
        "        \"objectId\": \"optional-identifier-2\",\n",
        "        \"features\": [\n",
        "            {\"name\": \"title\", \"value\": \"Super-speeds with Zero-RAM: Next Generation Large-Scale Optimization in Your Laptop\"}        \n",
        "        ],\n",
        "    },\n",
        "    {\n",
        "        \"objectId\": \"optional-identifier-3\",\n",
        "        \"features\": [\n",
        "            {\"name\": \"title\", \"value\": \"Why optional stopping is a problem for Bayesians\"}        \n",
        "        ],\n",
        "    }\n",
        "]\n",
        "\n",
        "\n",
        "inference_response = inference.create_inference_request(model_name, objects_to_be_classified, top_n=3)\n",
        "\n",
        "print()\n",
        "print(\"Inference request processed. Response:\")\n",
        "print()\n",
        "pprint(inference_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODUM5E1VKpft"
      },
      "source": [
        "We can see that the service now returns the `n-best` predictions for each label as indicated by the `top_n` parameter.\n",
        "\n",
        "In some cases, the predicted category has the special value `nan`. In the `arxiv.csv` data set, not all records have the full set of categories. Some records only have one label and some having up to three. The model learns this fact from the data and will occasionally suggest that a record should not have a label."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQg2g0reKpft"
      },
      "source": [
        "To learn how to execute inference calls without the SDK just using the underlying RESTful API, see [Inference without the SDK](#Inference-without-the-SDK)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WK8mxYodKpft"
      },
      "source": [
        "## Summary Exercise 01.4\n",
        "\n",
        "In exercise 01.4, we have covered the following topics:\n",
        "\n",
        "* How to deploy a previously trained model\n",
        "* How to execute inference requests against a deployed model\n",
        "\n",
        "You can find optional exercises related to exercise 01.4 [below](#Optional-Exercises-for-01.4)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KY1ror5jKpft"
      },
      "source": [
        "# Wrapping up\n",
        "\n",
        "In this workshop, we looked into the following topics:\n",
        "\n",
        "* Installation of the Python SDK for Data Attribute Recommendation\n",
        "* Modelling data with a DatasetSchema\n",
        "* Uploading data into a Dataset\n",
        "* Training a model\n",
        "* Predicting labels for unlabelled data\n",
        "\n",
        "Using these tools, we are able to solve the problem of missing Master Data attributes starting from just a CSV file containing training data.\n",
        "\n",
        "Feel free to revisit the workshop materials at any time. The [resources](#Resources) section below contains additional reading.\n",
        "\n",
        "If you would like to explore the additional capabilities of the SDK, visit the [optional exercises](#Optional-Exercises) below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpfRCk_dKpfu"
      },
      "source": [
        "## Cleanup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQ9wPkRuKpfu"
      },
      "source": [
        "During the course of the workshop, we have created several resources on the Data Attribute Recommendation Service:\n",
        "\n",
        "* DatasetSchema\n",
        "* Dataset\n",
        "* Job\n",
        "* Model\n",
        "* Deployment\n",
        "\n",
        "The SDK provides several methods to delete these resources. Note that there are dependencies between objects: you cannot delete a Dataset without deleting the Model beforehand.\n",
        "\n",
        "You will need to set `CLEANUP_SESSION = True` below to execute the cleanup."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PtAaDVOUKpfu"
      },
      "outputs": [],
      "source": [
        "# Clean up all resources created earlier\n",
        "\n",
        "CLEANUP_SESSION = False\n",
        "\n",
        "def cleanup_session():\n",
        "    model_manager.delete_deployment_by_id(deployment_id) # this can take a few seconds\n",
        "    model_manager.delete_model_by_name(model_name)\n",
        "    model_manager.delete_job_by_id(job_id)\n",
        "\n",
        "    data_manager.delete_dataset_by_id(dataset_id)\n",
        "    data_manager.delete_dataset_schema_by_id(dataset_schema_id)\n",
        "    print(\"DONE cleaning up!\")\n",
        "\n",
        "if CLEANUP_SESSION:\n",
        "    print(\"Cleaning up resources generated in this session.\")\n",
        "    cleanup_session()\n",
        "else:\n",
        "    print(\"Not cleaning up. Set 'CLEANUP_SESSION = True' above and run again!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRRaA2lgKpfu"
      },
      "source": [
        "## Resources\n",
        "\n",
        "*Back to [table of contents](#Table-of-Contents)*\n",
        "\n",
        "\n",
        "### Data Attribute Recommendation\n",
        "\n",
        "* [SAP Help Portal](https://help.sap.com/viewer/product/Data_Attribute_Recommendation/SHIP/en-US)\n",
        "* [API Reference](https://help.sap.com/viewer/105bcfd88921418e8c29b24a7a402ec3/SHIP/en-US/b45cf9b24fd042d082c16191aa938c8d.html)\n",
        "* [Tutorials using Postman - interact with the service RESTful API directly](https://developers.sap.com/mission.cp-aibus-data-attribute.html)\n",
        "* [Trial Account Limits](https://help.sap.com/viewer/105bcfd88921418e8c29b24a7a402ec3/SHIP/en-US/c03b561eea1744c9b9892b416037b99a.html)\n",
        "* [Metering and Pricing](https://help.sap.com/viewer/105bcfd88921418e8c29b24a7a402ec3/SHIP/en-US/1e093326a2764c298759fcb92c5b0500.html)\n",
        "* [Blog Post: How does AutoML work in Data Attribute Recommendation?](https://blogs.sap.com/2021/04/28/how-does-automl-works-in-data-attribute-recommendation/)\n",
        "* [Blog Post: Solving regression use-cases with Data Attribute Recommendation](https://blogs.sap.com/2021/11/14/solving-regression-use-cases-with-data-attribute-recommendation/)\n",
        "* [All Blog Posts on Data Attribute Recommendation](https://blogs.sap.com/tags/73554900100800002858/)\n",
        "\n",
        "### SDK Resources\n",
        "\n",
        "* [SDK source code on Github](https://github.com/SAP/data-attribute-recommendation-python-sdk)\n",
        "* [SDK documentation](https://data-attribute-recommendation-python-sdk.readthedocs.io/en/latest/)\n",
        "* [How to obtain support](https://github.com/SAP/data-attribute-recommendation-python-sdk/blob/master/README.md#how-to-obtain-support)\n",
        "* [Tutorials: Classify Data Records with the SDK for Data Attribute Recommendation](https://developers.sap.com/group.cp-aibus-data-attribute-sdk.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qL0VrpPKpfu"
      },
      "source": [
        "## Addendum"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOP5HNKPKpfu"
      },
      "source": [
        "### Inference without the SDK\n",
        "\n",
        "*Back to [table of contents](#Table-of-Contents)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXhwcLc_Kpfu"
      },
      "source": [
        "The Data Attribute Service exposes a RESTful API. The SDK we use in this workshop uses this API to interact with the DAR service.\n",
        "\n",
        "For custom integration, you can implement your own client for the API. The tutorial \"[Use Machine Learning to Classify Data Records]\" is a great way to explore the Data Attribute Recommendation API with the Postman REST client. Beyond the tutorial, the [API Reference] is a comprehensive documentation of the RESTful interface.\n",
        "\n",
        "[Use Machine Learning to Classify Data Records]: https://developers.sap.com/mission.cp-aibus-data-attribute.html\n",
        "\n",
        "[API Reference]: https://help.sap.com/viewer/105bcfd88921418e8c29b24a7a402ec3/SHIP/en-US/b45cf9b24fd042d082c16191aa938c8d.html\n",
        "\n",
        "To demonstrate the underlying API, the next example uses the `curl` command line tool to perform an inference request against the Inference API.\n",
        "\n",
        "The example uses the `jq` command to extract the credentials from the service. The authentication token is retrieved from the `uaa_url` and then used for the inference request."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aX1X9iUTKpfu"
      },
      "outputs": [],
      "source": [
        "# If the following example gives you errors that the jq or curl commands cannot be found,\n",
        "# you may be able to install them from conda by uncommenting one of the lines below:\n",
        "#%conda install -q jq\n",
        "#%conda install -q curl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BhZBNmMAKpfv",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "%%bash -s \"$model_name\" # Pass the python model_name variable as the first argument to shell script\n",
        "\n",
        "model_name=$1\n",
        "\n",
        "echo \"Model: $model_name\"\n",
        "\n",
        "key=$(cat key.json)\n",
        "url=$(echo $key | jq -r .url)\n",
        "uaa_url=$(echo $key | jq -r .uaa.url)\n",
        "clientid=$(echo $key | jq -r .uaa.clientid)\n",
        "clientsecret=$(echo $key | jq -r .uaa.clientsecret)\n",
        "\n",
        "echo \"Service URL: $url\"\n",
        "\n",
        "token_url=${uaa_url}/oauth/token?grant_type=client_credentials\n",
        "\n",
        "echo \"Obtaining token with clientid $clientid from $token_url\"\n",
        "\n",
        "bearer_token=$(curl \\\n",
        "                --silent --show-error \\\n",
        "                --user $clientid:$clientsecret \\\n",
        "                $token_url \\\n",
        "                | jq -r .access_token\n",
        "             )\n",
        "\n",
        "inference_url=${url}/inference/api/v3/models/${model_name}/versions/1\n",
        "\n",
        "echo \"Running inference request against endpoint $inference_url\"\n",
        "\n",
        "echo \"\"\n",
        "\n",
        "# We pass the token in the Authorization header.\n",
        "# The payload for the inference request is passed as\n",
        "# the body of the POST request below.\n",
        "# The output of the curl command is piped through `jq`\n",
        "# for pretty-printing\n",
        "curl \\\n",
        "    --silent --show-error \\\n",
        "    --header \"Authorization: Bearer ${bearer_token}\" \\\n",
        "    --header \"Content-Type: application/json\" \\\n",
        "    -XPOST \\\n",
        "    ${inference_url} \\\n",
        "    -d '{\n",
        "          \"objects\": [\n",
        "            {\n",
        "              \"features\": [\n",
        "                {\n",
        "                  \"name\": \"manufacturer\",\n",
        "                  \"value\": \"Energizer\"\n",
        "                },\n",
        "                {\n",
        "                  \"name\": \"description\",\n",
        "                  \"value\": \"Alkaline batteries; 1.5V\"\n",
        "                },\n",
        "                {\n",
        "                  \"name\": \"price\",\n",
        "                  \"value\": \"5.99\"\n",
        "                }\n",
        "              ]\n",
        "            }\n",
        "          ]\n",
        "        }' | jq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGTYzez-Kpfv"
      },
      "source": [
        "### Cleaning up a service instance\n",
        "\n",
        "*Back to [table of contents](#Table-of-Contents)*\n",
        "\n",
        "To clean all data on the service instance, you can run the following snippet. The code is self-contained and does not require you to execute any of the cells above. However, you will need to have the `key.json` containing a service key in place.\n",
        "\n",
        "You will need to set `CLEANUP_EVERYTHING = True` below to execute the cleanup.\n",
        "\n",
        "**NOTE: This will delete all data on the service instance!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4Xfrx7zKpfv"
      },
      "outputs": [],
      "source": [
        "CLEANUP_EVERYTHING = True\n",
        "\n",
        "def cleanup_everything():\n",
        "    import logging\n",
        "    import sys\n",
        "\n",
        "    logging.basicConfig(level=logging.INFO, stream=sys.stdout)\n",
        "\n",
        "    import json\n",
        "    import os\n",
        "\n",
        "    if not os.path.exists(\"key.json\"):\n",
        "        msg = \"key.json is not found. Please follow instructions above to create a service key of\"\n",
        "        msg += \" Data Attribute Recommendation. Then, upload it into the same directory where\"\n",
        "        msg += \" this notebook is saved.\"\n",
        "        print(msg)\n",
        "        raise ValueError(msg)\n",
        "\n",
        "    with open(\"key.json\") as file_handle:\n",
        "        key = file_handle.read()\n",
        "        SERVICE_KEY = json.loads(key)\n",
        "\n",
        "    from sap.aibus.dar.client.model_manager_client import ModelManagerClient\n",
        "\n",
        "    model_manager = ModelManagerClient.construct_from_service_key(SERVICE_KEY)\n",
        "\n",
        "    for deployment in model_manager.read_deployment_collection()[\"deployments\"]:\n",
        "        model_manager.delete_deployment_by_id(deployment[\"id\"])\n",
        "\n",
        "    for model in model_manager.read_model_collection()[\"models\"]:\n",
        "        model_manager.delete_model_by_name(model[\"name\"])\n",
        "\n",
        "    for job in model_manager.read_job_collection()[\"jobs\"]:\n",
        "        model_manager.delete_job_by_id(job[\"id\"])\n",
        "\n",
        "    from sap.aibus.dar.client.data_manager_client import DataManagerClient\n",
        "\n",
        "    data_manager = DataManagerClient.construct_from_service_key(SERVICE_KEY)\n",
        "\n",
        "    for dataset in data_manager.read_dataset_collection()[\"datasets\"]:\n",
        "        data_manager.delete_dataset_by_id(dataset[\"id\"])\n",
        "\n",
        "    for dataset_schema in data_manager.read_dataset_schema_collection()[\"datasetSchemas\"]:\n",
        "        data_manager.delete_dataset_schema_by_id(dataset_schema[\"id\"])\n",
        "        \n",
        "    print(\"Cleanup done!\")\n",
        "\n",
        "if CLEANUP_EVERYTHING:\n",
        "    print(\"Cleaning up all resources in this service instance.\")\n",
        "    cleanup_everything()\n",
        "else:\n",
        "    print(\"Not cleaning up. Set 'CLEANUP_EVERYTHING = True' above and run again.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6D_KBCpfKpfv"
      },
      "source": [
        "### Optional Exercises\n",
        "\n",
        "*Back to [table of contents](#Table-of-Contents)*\n",
        "\n",
        "To work with the optional exercises, create a new cell in the Jupyter notebook by clicking the `+` button in the menu above or by using the `b` shortcut on your keyboard. You can then enter your code in the new cell and execute it.\n",
        "\n",
        "#### Optional Exercises for 01.2\n",
        "\n",
        "##### DatasetSchemas\n",
        "\n",
        "Use the [`DataManagerClient.read_dataset_schema_by_id()`](https://data-attribute-recommendation-python-sdk.readthedocs.io/en/latest/api.html#sap.aibus.dar.client.data_manager_client.DataManagerClient.read_dataset_schema_by_id) and the [`DataManagerClient.read_dataset_schema_collection()`](https://data-attribute-recommendation-python-sdk.readthedocs.io/en/latest/api.html#sap.aibus.dar.client.data_manager_client.DataManagerClient.read_dataset_schema_collection) methods to list the newly created and all DatasetSchemas, respectively.\n",
        "\n",
        "##### Datasets\n",
        "\n",
        "Use the [`DataManagerClient.read_dataset_by_id()`](https://data-attribute-recommendation-python-sdk.readthedocs.io/en/latest/api.html#sap.aibus.dar.client.data_manager_client.DataManagerClient.read_dataset_by_id) and the [`DataManagerClient.read_dataset_collection()`](https://data-attribute-recommendation-python-sdk.readthedocs.io/en/latest/api.html#sap.aibus.dar.client.data_manager_client.DataManagerClient.read_dataset_collection) methods to inspect the newly created dataset.\n",
        "\n",
        "Instead of using two separate methods to upload data and wait for validation to finish, you can also use [`DataManagerClient.upload_data_and_validate()`](https://data-attribute-recommendation-python-sdk.readthedocs.io/en/latest/api.html#sap.aibus.dar.client.data_manager_client.DataManagerClient.upload_data_and_validate).\n",
        "\n",
        "#### Optional Exercises for 01.3\n",
        "\n",
        "##### ModelTemplates\n",
        "\n",
        "Use the [`ModelManagerClient.read_model_template_collection()`](https://data-attribute-recommendation-python-sdk.readthedocs.io/en/latest/api.html#sap.aibus.dar.client.model_manager_client.ModelManagerClient.read_model_template_collection) to list all existing model templates.\n",
        "\n",
        "##### Jobs\n",
        "\n",
        "Use [`ModelManagerClient.read_job_by_id()`](https://data-attribute-recommendation-python-sdk.readthedocs.io/en/latest/api.html#sap.aibus.dar.client.model_manager_client.ModelManagerClient.read_job_by_id) and [`ModelManagerClient.read_job_collection()`](https://data-attribute-recommendation-python-sdk.readthedocs.io/en/latest/api.html#sap.aibus.dar.client.model_manager_client.ModelManagerClient.read_job_collection) to inspect the job we just created.\n",
        "\n",
        "The entire process of uploading the data and starting the training is also available as a single method call in [`ModelCreator.create()`](https://data-attribute-recommendation-python-sdk.readthedocs.io/en/latest/api.html#sap.aibus.dar.client.workflow.model.ModelCreator.create).\n",
        "\n",
        "#### Optional Exercises for 01.4\n",
        "\n",
        "##### Deployments\n",
        "\n",
        "Use [`ModelManagerClient.read_deployment_by_id()`](https://data-attribute-recommendation-python-sdk.readthedocs.io/en/latest/api.html#sap.aibus.dar.client.model_manager_client.ModelManagerClient.read_deployment_by_id) and [`ModelManagerClient.read_deployment_collection()`](https://data-attribute-recommendation-python-sdk.readthedocs.io/en/latest/api.html#sap.aibus.dar.client.model_manager_client.ModelManagerClient.read_deployment_collection) to inspect the Deployment.\n",
        "\n",
        "Use the [`ModelManagerclient.lookup_deployment_id_by_model_name()`](https://data-attribute-recommendation-python-sdk.readthedocs.io/en/latest/api.html#sap.aibus.dar.client.model_manager_client.ModelManagerClient.lookup_deployment_id_by_model_name) method to find the deployment ID for a given model name.\n",
        "\n",
        "##### Inference\n",
        "\n",
        "Use the [`InferenceClient.do_bulk_inference()`](https://data-attribute-recommendation-python-sdk.readthedocs.io/en/latest/api.html#sap.aibus.dar.client.inference_client.InferenceClient.do_bulk_inference) method to process more than fifty objects at a time. Note how the data format returned changes."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "bkk5nSzYKpff",
        "JXPp8AH2Kpfh",
        "8vwjzd59Kpfn",
        "NWyZIjzLKpfn",
        "a5Lt67cuKpfo",
        "6F0ko2U9Kpfo",
        "nzU3blu7Kpfq",
        "NWRvcnAVKpfq",
        "n_nTqMTBKpfq",
        "NT2YyY-5Kpfq",
        "ZFZqPeRQKpfs",
        "WK8mxYodKpft",
        "KpfRCk_dKpfu",
        "BRRaA2lgKpfu",
        "2qL0VrpPKpfu",
        "FOP5HNKPKpfu",
        "RGTYzez-Kpfv",
        "6D_KBCpfKpfv"
      ],
      "name": "Data_Attribute_Recommendation_Generic_Model_Template.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
