{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "name": "Data_Attribute_Recommendation_Regression_Model_Template.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwrJnkCcq-z0"
      },
      "source": [
        "# Data Attribute Recommendation - TechED 2020 INT260\n",
        "\n",
        "Getting started with the Python SDK for the Data Attribute Recommendation service."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mOG0BN3q-z5"
      },
      "source": [
        "## Business Scenario\n",
        "\n",
        "We will consider a business scenario involving product master data. The creation and maintenance of this product master data requires the careful manual selection of the correct categories for a given product from a pre-defined hierarchy of product categories.\n",
        "\n",
        "In this workshop, we will explore how to automate this tedious manual task with the Data Attribute Recommendation service."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1IKc4H9q-z6"
      },
      "source": [
        "<video controls src=\"videos/dar_prediction_material_table.mp4\"/>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwTXj6URq-z6"
      },
      "source": [
        "This workshop will cover:\n",
        "    \n",
        "* Data Upload\n",
        "* Model Training and Deployment\n",
        "* Inference Requests\n",
        "    \n",
        "We will work through a basic example of how to achieve these tasks using the [Python SDK for Data Attribute Recommendation](https://github.com/SAP/data-attribute-recommendation-python-sdk).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aZ-dcKrq-z7"
      },
      "source": [
        "*Note: if you are doing several runs of this notebook on a trial account, you may see errors stating 'The resource can no longer be used. Usage limit has been reached'. It can be beneficial to [clean up the service instance](#Cleaning-up-a-service-instance) to free up limited trial resources acquired by an earlier run of the notebook. [Some limits](https://help.sap.com/viewer/105bcfd88921418e8c29b24a7a402ec3/SHIP/en-US/c03b561eea1744c9b9892b416037b99a.html) cannot be reset this way.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpQtE58eq-z7"
      },
      "source": [
        "## Table of Contents\n",
        "\n",
        "* [Exercise 01.1](#Exercise-01.1) - Installing the SDK and preparing the service key\n",
        "    * [Creating a service instance and key on BTP Trial](#Creating-a-service-instance-and-key)\n",
        "    * [Installing the SDK](#Installing-the-SDK)\n",
        "    * [Loading the service key into your Jupyter Notebook](#Loading-the-service-key-into-your-Jupyter-Notebook)\n",
        "* [Exercise 01.2](#Exercise-01.2) - Uploading the data\n",
        "* [Exercise 01.3](#Exercise-01.3) - Training the model\n",
        "* [Exercise 01.4](#Exercise-01.4) - Deploying the Model and predicting labels\n",
        "* [Resources](#Resources) - Additional reading\n",
        "* [Cleaning up a service instance](#Cleaning-up-a-service-instance) - Clean up all resources on the service instance\n",
        "* [Optional Exercises](#Optional-Exercises) - Optional exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4hrCmUhq-z8"
      },
      "source": [
        "## Requirements\n",
        "\n",
        "\n",
        "See the [README in the Github repository for this workshop](https://github.com/SAP-samples/teched2020-INT260/blob/master/exercises/ex1-DAR/README.md)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIE4U09vq-z8"
      },
      "source": [
        "# Exercise 01.1\n",
        "\n",
        "*Back to [table of contents](#Table-of-Contents)*\n",
        "\n",
        "In exercise 01.1, we will install the SDK and prepare the service key."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lg-q4Sqfq-z9"
      },
      "source": [
        "## Creating a service instance and key on BTP Trial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPIoP_fUq-z9"
      },
      "source": [
        "Please log in to your trial account: https://cockpit.eu10.hana.ondemand.com/trial/\n",
        "\n",
        "In the your global account screen, go to the \"Boosters\" tab:\n",
        "\n",
        "![trial_booster.png](attachment:trial_booster.png)\n",
        "\n",
        "*Boosters are only available on the Trial landscape. If you are using a production environment, please follow this tutorial to manually [create a service instance and a service key](https://developers.sap.com/tutorials/cp-aibus-dar-service-instance.html)*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVGdbhrMq-z9"
      },
      "source": [
        "In the Boosters tab, enter \"Data Attribute Recommendation\" into the search box. Then, select the\n",
        "service tile from the search results: \n",
        "    \n",
        "![trial_locate_dar_booster.png](attachment:trial_locate_dar_booster.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WjYUR88q-z9"
      },
      "source": [
        "The resulting screen shows details of the booster pack. Here, click the \"Start\" button and wait a few seconds.\n",
        "\n",
        "![trial_start_booster.png](attachment:trial_start_booster.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ye3OR-kvq-z-"
      },
      "source": [
        "Once the booster is finished, click the \"go to Service Key\" link to obtain your service key.\n",
        "\n",
        "![trial_booster_finished.png](attachment:trial_booster_finished.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmkt-K_Zq-z-"
      },
      "source": [
        "Finally, download the key and save it to disk.\n",
        "\n",
        "![trial_download_key.png](attachment:trial_download_key.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_6h2IBSq-z-"
      },
      "source": [
        "## Installing the SDK"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmYq2jA3q-z_"
      },
      "source": [
        "The Data Attribute Recommendation SDK is available from the Python package repository. It can be installed with the standard `pip` tool:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGCJdycrq-z_"
      },
      "source": [
        "! pip install data-attribute-recommendation-sdk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4GSyf6cq-0A"
      },
      "source": [
        "*Note: If you are not using a Jupyter notebook, but instead a regular Python development environment, we recommend using a Python virtual environment to set up your development environment. Please see [the dedicated tutorial to learn how to install the SDK inside a Python virtual environment](https://developers.sap.com/tutorials/cp-aibus-dar-sdk-setup.html).*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2y5OJaUq-0B"
      },
      "source": [
        "## Loading the service key into your Jupyter Notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSxu2krFq-0B"
      },
      "source": [
        "Once you downloaded the service key from the Cockpit, upload it to your notebook environment. The service key must be uploaded to same directory where the `teched2020-INT260_Data_Attribute_Recommendation.ipynb` is stored.\n",
        "\n",
        "We first navigate to the file browser in Jupyter. On the top of your Jupyter notebook, right-click on the Jupyter logo and open in a new tab.\n",
        "\n",
        "![service_key_main_jupyter_page.png](attachment:service_key_main_jupyter_page.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdca3MEzq-0B"
      },
      "source": [
        "**In the file browser, navigate to the directory where the `teched2020-INT260_Data_Attribute_Recommendation.ipynb` notebook file is stored. The service key must reside next to this file.**\n",
        "\n",
        "In the Jupyter file browser, click the **Upload** button (1). In the file selection dialog that opens, select the `defaultKey_*.json` file you downloaded previously from the SAP Cloud Platform Cockpit. Rename the file to `key.json`. \n",
        "\n",
        "Confirm the upload by clicking on the second **Upload** button (2).\n",
        "\n",
        "![service_key_upload.png](attachment:service_key_upload.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrxMuURXq-0C"
      },
      "source": [
        "The service key contains your credentials to access the service. Please treat this as carefully as you would treat any password. We keep the service key as a separate file outside this notebook to avoid leaking the secret credentials.\n",
        "\n",
        "The service key is a JSON file. We will load this file once and use the credentials throughout this workshop. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izuKS1nmq-0C"
      },
      "source": [
        "# First, set up logging so we can see the actions performed by the SDK behind the scenes\n",
        "import logging\n",
        "import sys\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, stream=sys.stdout)\n",
        "\n",
        "from pprint import pprint # for nicer output formatting"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8o2h_Ilxq-0D"
      },
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "if not os.path.exists(\"dar_key.json\"):\n",
        "    msg = \"key.json is not found. Please follow instructions above to create a service key of\"\n",
        "    msg += \" Data Attribute Recommendation. Then, upload it into the same directory where\"\n",
        "    msg += \" this notebook is saved.\"\n",
        "    print(msg)\n",
        "    raise ValueError(msg)\n",
        "\n",
        "with open(\"dar_key.json\") as file_handle:\n",
        "    key = file_handle.read()\n",
        "    SERVICE_KEY = json.loads(key)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxMfN2-jq-0D"
      },
      "source": [
        "## Summary Exercise 01.1\n",
        "\n",
        "In exercise 01.1, we have covered the following topics:\n",
        "\n",
        "* How to install the Python SDK for Data Attribute Recommendation\n",
        "* How to obtain a service key for the Data Attribute Recommendation service"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQ8B0lJ6q-0D"
      },
      "source": [
        "# Exercise 01.2\n",
        "\n",
        "*Back to [table of contents](#Table-of-Contents)*\n",
        "*To perform this exercise, you need to execute the code in all previous exercises.*\n",
        "\n",
        "In exercise 01.2, we will upload our demo dataset to the service."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygzx_LXUq-0E"
      },
      "source": [
        "## The Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JiFx8npq-0E"
      },
      "source": [
        "### Obtaining the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNGQXQLGq-0F"
      },
      "source": [
        "The dataset we use in this workshop is a CSV file containing product master data. The original data was released by BestBuy, a retail company, under [Creative Commons Zero v1.0 Universal](https://github.com/BestBuyAPIs/open-data-set/blob/master/LICENSE). This makes it ideal for first experiments with the Data Attribute Recommendation service."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUwEoMxpq-0F"
      },
      "source": [
        "The dataset can be downloaded directly from Github using the following command:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaRZ5qt1q-0F"
      },
      "source": [
        "! wget -O bestBuy.csv \"https://raw.githubusercontent.com/SAP-samples/data-attribute-recommendation-postman-tutorial-sample/master/Tutorial_Example_Dataset.csv\"\n",
        "# If you receive a \"command not found\" error (i.e. on Windows), try curl instead of wget:\n",
        "# ! curl -o bestBuy.csv \"https://raw.githubusercontent.com/SAP-samples/data-attribute-recommendation-postman-tutorial-sample/master/Tutorial_Example_Dataset.csv\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_b7t4FCZq-0H"
      },
      "source": [
        "Let's inspect the data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agow65cNq-0H"
      },
      "source": [
        "# if you are experiencing an import error here, run the following in a new cell:\n",
        "# ! pip install pandas\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"bestBuy.csv\")\n",
        "df.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDR52gQbq-0J"
      },
      "source": [
        "df.iloc[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGLCZyWfq-0K"
      },
      "source": [
        "print()\n",
        "print(f\"Data has {df.shape[0]} rows and {df.shape[1]} columns.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIMp3vJAq-0M"
      },
      "source": [
        "The CSV contains the several products. For each product, the description, the manufacturer, three levels of the products hierarchy and the price are given. We use the `manufacturer`, `description`, `level1_category`, `level2_category`, `level3_category` to predict `price`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boAtJjlvq-0M"
      },
      "source": [
        "We will use the Data Attribute Recommendation service to predict the **price** for a given product based on its **description**, **manufacturer**, **level1_category**, **level2_category**, and **level3_category**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFsnpAE1q-0N"
      },
      "source": [
        "### Creating the DatasetSchema"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kW3pxANQq-0N"
      },
      "source": [
        "We first have to describe the shape of our data by creating a DatasetSchema. This schema informs the service about the individual column types found in the CSV. We also describe which are the target columns used for training. These columns will be later predicted. In our case, these are the three category columns.\n",
        "\n",
        "The service currently supports three column types: **text**, **category** and **number**. For prediction, only **category** and **number** types are currently supported.\n",
        "\n",
        "A DatasetSchema for the BestBuy dataset looks as follows:\n",
        "\n",
        "```json\n",
        "{\n",
        "    \"features\": [\n",
        "        {\"label\": \"manufacturer\", \"type\": \"CATEGORY\"},\n",
        "        {\"label\": \"description\", \"type\": \"TEXT\"},\n",
        "        {\"label\": \"level1_category\", \"type\": \"CATEGORY\"},\n",
        "        {\"label\": \"level2_category\", \"type\": \"CATEGORY\"},\n",
        "        {\"label\": \"level3_category\", \"type\": \"CATEGORY\"}\n",
        "        \n",
        "    ],\n",
        "    \"labels\": [\n",
        "        {\"label\": \"price\", \"type\": \"NUMBER\"}\n",
        "    ],\n",
        "    \"name\": \"bestbuy-price-prediction\",\n",
        "}\n",
        "```\n",
        "\n",
        "We will now upload this DatasetSchema to the Data Attribute Recommendation service. The SDK provides the\n",
        "[`DataManagerClient.create_dataset_schema()`](https://data-attribute-recommendation-python-sdk.readthedocs.io/en/latest/api.html#sap.aibus.dar.client.data_manager_client.DataManagerClient.create_dataset_schema) method for this purpose.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NkluOHCq-0N"
      },
      "source": [
        "from sap.aibus.dar.client.data_manager_client import DataManagerClient\n",
        "\n",
        "dataset_schema = {\n",
        "    \"features\": [\n",
        "        {\"label\": \"manufacturer\", \"type\": \"CATEGORY\"},\n",
        "        {\"label\": \"description\", \"type\": \"TEXT\"},\n",
        "        {\"label\": \"level1_category\", \"type\": \"CATEGORY\"},\n",
        "        {\"label\": \"level2_category\", \"type\": \"CATEGORY\"},\n",
        "        {\"label\": \"level3_category\", \"type\": \"CATEGORY\"}\n",
        "        \n",
        "    ],\n",
        "    \"labels\": [\n",
        "        {\"label\": \"price\", \"type\": \"NUMBER\"}\n",
        "    ],\n",
        "    \"name\": \"bestbuy-price-prediction\",\n",
        "}\n",
        "\n",
        "\n",
        "data_manager = DataManagerClient.construct_from_service_key(SERVICE_KEY)\n",
        "response = data_manager.create_dataset_schema(dataset_schema)\n",
        "dataset_schema_id = response[\"id\"]\n",
        "\n",
        "print()\n",
        "print(\"DatasetSchema created:\")\n",
        "\n",
        "pprint(response)\n",
        "\n",
        "print()\n",
        "print(f\"DatasetSchema ID: {dataset_schema_id}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQO6z4hAq-0O"
      },
      "source": [
        "The API responds with the newly created DatasetSchema resource. The service assigned an ID to the schema. We save this ID in a variable, as we will need it when we upload the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lz9s492nq-0O"
      },
      "source": [
        "### Uploading the Data to the service"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppT4Ka4sq-0P"
      },
      "source": [
        "The [`DataManagerClient`](https://data-attribute-recommendation-python-sdk.readthedocs.io/en/latest/api.html#sap.aibus.dar.client.data_manager_client.DataManagerClient) class is also responsible for uploading data to the service. This data must fit to an existing DatasetSchema. After uploading the data, the service will validate the Dataset against the DataSetSchema in a background process. The data must be a CSV file which can optionally be `gzip` compressed.\n",
        "\n",
        "We will now upload our `bestBuy.csv` file, using the DatasetSchema which we created earlier.\n",
        "\n",
        "Data upload is a two-step process. We first create the Dataset using [`DataManagerClient.create_dataset()`](https://data-attribute-recommendation-python-sdk.readthedocs.io/en/latest/api.html#sap.aibus.dar.client.data_manager_client.DataManagerClient.create_dataset). Then we can upload data to the Dataset using the [`DataManagerClient.upload_data_to_dataset()`](https://data-attribute-recommendation-python-sdk.readthedocs.io/en/latest/api.html#sap.aibus.dar.client.data_manager_client.DataManagerClient.upload_data_to_dataset) method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JpCyRpsq-0Q"
      },
      "source": [
        "dataset_resource = data_manager.create_dataset(\"my-bestbuy-dataset\", dataset_schema_id)\n",
        "dataset_id = dataset_resource[\"id\"]\n",
        "\n",
        "print()\n",
        "print(\"Dataset created:\")\n",
        "\n",
        "pprint(dataset_resource)\n",
        "\n",
        "print()\n",
        "print(f\"Dataset ID: {dataset_id}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyHupeX9q-0Q"
      },
      "source": [
        "# Compress file first for a faster upload\n",
        "! gzip -9 -c bestBuy.csv > bestBuy.csv.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucTnwgDGq-0Q"
      },
      "source": [
        "Note that the data upload can take a few minutes. Please do not restart the process while the cell is still running."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4suDaiVPq-0R"
      },
      "source": [
        "# Open in binary mode.\n",
        "with open('bestBuy.csv.gz', 'rb') as file_handle:\n",
        "    dataset_resource = data_manager.upload_data_to_dataset(dataset_id, file_handle)\n",
        "\n",
        "print()\n",
        "print(\"Dataset after data upload:\")\n",
        "print()\n",
        "pprint(dataset_resource)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5sKEv39q-0R"
      },
      "source": [
        "Note that the Dataset status changed from `NO_DATA` to `VALIDATING`.\n",
        "\n",
        "Dataset validation is a background process. The status will eventually change from `VALIDATING` to `SUCCEEDED`.\n",
        "The SDK provides the [`DataManagerClient.wait_for_dataset_validation()`](https://data-attribute-recommendation-python-sdk.readthedocs.io/en/latest/api.html#sap.aibus.dar.client.data_manager_client.DataManagerClient.wait_for_dataset_validation) method to poll for the Dataset validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hPf-KyIq-0R"
      },
      "source": [
        "dataset_resource = data_manager.wait_for_dataset_validation(dataset_id)\n",
        "\n",
        "print()\n",
        "print(\"Dataset after validation has finished:\")\n",
        "\n",
        "print()\n",
        "pprint(dataset_resource)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMvz-L4hq-0R"
      },
      "source": [
        "If the status is `FAILED` instead of `SUCCEEDED`, then the `validationMessage` will contain details about the validation failure."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZD5rJLYDq-0R"
      },
      "source": [
        "To better understand the Dataset lifecycle, refer to the [corresponding document on help.sap.com](https://help.sap.com/viewer/105bcfd88921418e8c29b24a7a402ec3/SHIP/en-US/a9b7429687a04e769dbc7955c6c44265.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3E1613RBq-0S"
      },
      "source": [
        "## Summary Exercise 01.2\n",
        "\n",
        "In exercise 01.2, we have covered the following topics:\n",
        "\n",
        "* How to create a DatasetSchema\n",
        "* How to upload a Dataset to the service\n",
        "\n",
        "You can find optional exercises related to exercise 01.2 [below](#Optional-Exercises-for-01.2)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swb9VHxmq-0S"
      },
      "source": [
        "# Exercise 01.3\n",
        "\n",
        "*Back to [table of contents](#Table-of-Contents)*\n",
        "\n",
        "*To perform this exercise, you need to execute the code in all previous exercises.*\n",
        "\n",
        "In exercise 01.3, we will train the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKdX7-sPq-0S"
      },
      "source": [
        "## Training the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tf6j7Vk3q-0S"
      },
      "source": [
        "The Dataset is now uploaded and has been validated successfully by the service.\n",
        "\n",
        "To train a machine learning model, we first need to select the correct model template."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5-GkfShq-0S"
      },
      "source": [
        "### Selecting the right ModelTemplate\n",
        "\n",
        "The Data Attribute Recommendation service currently supports four different ModelTemplates:\n",
        "\n",
        "| ID                                   | Name                  | Description                                                               |\n",
        "|--------------------------------------|---------------------------|---------------------------------------------------------------------------|\n",
        "| d7810207-ca31-4d4d-9b5a-841a644fd81f | **Hierarchical template** | Recommended for the prediction of multiple classes that form a hierarchy. |\n",
        "| 223abe0f-3b52-446f-9273-f3ca39619d2c | **Generic template**      | Generic neural network for multi-label, multi-class classification.       |\n",
        "| 188df8b2-795a-48c1-8297-37f37b25ea00 | **AutoML template**      | Finds the [best traditional machine learning model out of several traditional algorithms](https://blogs.sap.com/2021/04/28/how-does-automl-works-in-data-attribute-recommendation/). Single label only. |\n",
        "| bdbcd699-4419-40a5-abb8-e7ad43dde49b | **Regression template**      | Predict the numeric value of a field. Single label only. |\n",
        "\n",
        "\n",
        "We are building a model to predict the price of the product - the **Regression Template** is correct for this scenario. \n",
        "\n",
        "Refer to the [official documentation on ModelTemplates](https://help.sap.com/viewer/105bcfd88921418e8c29b24a7a402ec3/SHIP/en-US/1e76e8c636974a06967552c05d40e066.html) to learn more. Additional model templates may be added over time, so check back regularly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lzhzuYgq-0S"
      },
      "source": [
        "## Starting the training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUGZWCeJq-0T"
      },
      "source": [
        "When working with models, we use the [`ModelManagerClient`](https://data-attribute-recommendation-python-sdk.readthedocs.io/en/latest/api.html#sap.aibus.dar.client.model_manager_client.ModelManagerClient) class.\n",
        "\n",
        "To start the training, we need the IDs of the dataset and the desired model template. We also have to provide a name for the model.\n",
        "The [`ModelManagerClient.create_job()`](https://data-attribute-recommendation-python-sdk.readthedocs.io/en/latest/api.html#sap.aibus.dar.client.model_manager_client.ModelManagerClient.create_job) method launches the training Job.\n",
        "\n",
        "*Only one model of a given name can exist. If you receive a message stating 'The model name specified is already in use', you either have to remove the job and its associated model first or you have to change the `model_name` variable name below. You can also [clean up the entire service instance](#Cleaning-up-a-service-instance).*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LA8nvn6Aq-0T"
      },
      "source": [
        "from sap.aibus.dar.client.model_manager_client import ModelManagerClient\n",
        "from sap.aibus.dar.client.exceptions import DARHTTPException\n",
        "\n",
        "model_manager = ModelManagerClient.construct_from_service_key(SERVICE_KEY)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ow_swR6Aq-0T"
      },
      "source": [
        "model_template_collection = model_manager.read_model_template_collection()\n",
        "pprint(model_template_collection)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTae6z27q-0T"
      },
      "source": [
        "model_template_id = \"bdbcd699-4419-40a5-abb8-e7ad43dde49b\" # regression template\n",
        "model_name = \"bestbuy-regression-model\"\n",
        "\n",
        "job_resource = model_manager.create_job(model_name, dataset_id, model_template_id)\n",
        "job_id = job_resource['id']\n",
        "\n",
        "print()\n",
        "print(\"Job resource:\")\n",
        "print()\n",
        "\n",
        "pprint(job_resource)\n",
        "\n",
        "print()\n",
        "print(f\"ID of submitted Job: {job_id}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hk0tJIjcq-0U"
      },
      "source": [
        "The job is now running in the background. Similar to the DatasetValidation, we have to poll the job until it succeeds.\n",
        "The SDK provides the [`ModelManagerClient.wait_for_job()`](https://data-attribute-recommendation-python-sdk.readthedocs.io/en/latest/api.html#sap.aibus.dar.client.model_manager_client.ModelManagerClient.wait_for_job) method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNWGXSUtq-0U"
      },
      "source": [
        "job_resource = model_manager.wait_for_job(job_id)\n",
        "\n",
        "print()\n",
        "\n",
        "print(\"Job resource after training is finished:\")\n",
        "\n",
        "pprint(job_resource)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnIdo1CIq-0U"
      },
      "source": [
        "To better understand the Training Job lifecycle, see the [corresponding document on help.sap.com](https://help.sap.com/viewer/105bcfd88921418e8c29b24a7a402ec3/SHIP/en-US/0fc40aa077ce4c708c1e5bfc875aa3be.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMVCEHeQq-0U"
      },
      "source": [
        "## Intermission\n",
        "\n",
        "The model training will take between 5 and 10 minutes.\n",
        "\n",
        "In the meantime, we can explore the available [resources](#Resources) for both the service and the SDK."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPA-LDRLq-0U"
      },
      "source": [
        "## Inspecting the Model\n",
        "\n",
        "Once the training job is finished successfully, we can inspect the model using [`ModelManagerClient.read_model_by_name()`](https://data-attribute-recommendation-python-sdk.readthedocs.io/en/latest/api.html#sap.aibus.dar.client.model_manager_client.ModelManagerClient.read_model_by_name).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmVe7gLxq-0U"
      },
      "source": [
        "model_resource = model_manager.read_model_by_name(model_name)\n",
        "\n",
        "print()\n",
        "pprint(model_resource)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_i4Uyxhq-0V"
      },
      "source": [
        "In the model resource, the `validationResult` key provides information about model performance. You can also use these metrics to compare performance of different [ModelTemplates](#Selecting-the-right-ModelTemplate) or different datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7AwkbC2q-0V"
      },
      "source": [
        "## Summary Exercise 01.3\n",
        "\n",
        "In exercise 01.3, we have covered the following topics:\n",
        "\n",
        "* How to select the appropriate ModelTemplate\n",
        "* How to train a Model from a previously uploaded Dataset\n",
        "\n",
        "You can find optional exercises related to exercise 01.3 [below](#Optional-Exercises-for-01.3)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHXxrUMjq-0V"
      },
      "source": [
        "# Exercise 01.4\n",
        "\n",
        "*Back to [table of contents](#Table-of-Contents)*\n",
        "\n",
        "*To perform this exercise, you need to execute the code in all previous exercises.*\n",
        "\n",
        "In exercise 01.4, we will deploy the model and predict labels for some unlabeled data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWjnkGP0q-0V"
      },
      "source": [
        "## Deploying the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lELaYmXaq-0V"
      },
      "source": [
        "The training job has finished and the model is ready to be deployed. By deploying the model, we create a server process in the background on the Data Attribute Recommendation service which will serve inference requests.\n",
        "\n",
        "In the SDK, the [`ModelManagerClient.create_deployment()`](https://data-attribute-recommendation-python-sdk.readthedocs.io/en/latest/api.html#module-sap.aibus.dar.client.model_manager_client) method lets us create a Deployment.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "_BA8zdv5q-0V"
      },
      "source": [
        "model_manager.read_model_collection()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "3a-EM8Opq-0V"
      },
      "source": [
        "model_manager.read_job_collection()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7I_32n1q-0W"
      },
      "source": [
        "model_manager.read_deployment_collection()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fly8su4sq-0W"
      },
      "source": [
        "deployment_resource =  model_manager.create_deployment(model_name)\n",
        "deployment_id = deployment_resource[\"id\"]\n",
        "\n",
        "print()\n",
        "print(\"Deployment resource:\")\n",
        "print()\n",
        "\n",
        "pprint(deployment_resource)\n",
        "\n",
        "print(f\"Deployment ID: {deployment_id}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tz1DH6l4q-0W"
      },
      "source": [
        "*Note: if you are using a trial account and you see errors such as 'The resource can no longer be used. Usage limit has been reached', consider [cleaning up the service instance](#Cleaning-up-a-service-instance) to free up limited trial resources.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ux2pfhKWq-0X"
      },
      "source": [
        "Similar to the data upload and the training job, model deployment is an asynchronous process. We have to poll the API until the Deployment is in status `SUCCEEDED`. The SDK provides the [`ModelManagerClient.wait_for_deployment()`](https://data-attribute-recommendation-python-sdk.readthedocs.io/en/latest/api.html#sap.aibus.dar.client.model_manager_client.ModelManagerClient.wait_for_deployment) for this purposes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgcEFpwiq-0X"
      },
      "source": [
        "deployment_resource = model_manager.wait_for_deployment(deployment_id)\n",
        "\n",
        "print()\n",
        "print(\"Finished deployment resource:\")\n",
        "print()\n",
        "\n",
        "pprint(deployment_resource)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NTKUc1mq-0X"
      },
      "source": [
        "Once the Deployment is in status `SUCCEEDED`, we can run inference requests."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BT16Q9_Lq-0X"
      },
      "source": [
        "To better understand the Deployment lifecycle, see the [corresponding document on help.sap.com](https://help.sap.com/viewer/105bcfd88921418e8c29b24a7a402ec3/SHIP/en-US/f473b5b19a3b469e94c40eb27623b4f0.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbyhzqbLq-0X"
      },
      "source": [
        "*For trial users: the deployment will be stopped after 8 hours. You can restart it by deleting the deployment and creating a new one for your model. The [`ModelManagerClient.ensure_deployment_exists()`](https://help.sap.com/viewer/105bcfd88921418e8c29b24a7a402ec3/SHIP/en-US/c03b561eea1744c9b9892b416037b99a.html) method will delete and re-create automatically. Then, you need to poll until the deployment is succeeded using [`ModelManagerClient.wait_for_deployment()`](https://data-attribute-recommendation-python-sdk.readthedocs.io/en/latest/api.html#sap.aibus.dar.client.model_manager_client.ModelManagerClient.wait_for_deployment) as above.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTQ5z_2fq-0X"
      },
      "source": [
        "## Executing Inference requests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYAzwFPAq-0Y"
      },
      "source": [
        "With a single inference request, we can send up to 50 objects to the service to predict the labels. The data send to the service must match the `features` section of the DatasetSchema created earlier. The `labels` defined inside of the DatasetSchema will be predicted for each object and returned as a response to the request.\n",
        "\n",
        "In the SDK, the [`InferenceClient.create_inference_request()`](https://data-attribute-recommendation-python-sdk.readthedocs.io/en/latest/api.html#sap.aibus.dar.client.inference_client.InferenceClient.create_inference_request) method handles submission of inference requests."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLqo6LJEq-0Y"
      },
      "source": [
        "from sap.aibus.dar.client.inference_client import InferenceClient\n",
        "\n",
        "inference = InferenceClient.construct_from_service_key(SERVICE_KEY)\n",
        "\n",
        "objects_to_be_classified = [\n",
        "    {\n",
        "        \"features\": [\n",
        "            {\"name\": \"manufacturer\", \"value\": \"Energizer\"},\n",
        "            {\"name\": \"description\", \"value\": \"Compatible with select electronic devices; AAA size; DURALOCK Power Preserve technology; 4-pack\"},\n",
        "            {\"name\": \"level1_category\", \"value\":  \"Connected Home & Housewares\"},\n",
        "            {\"name\": \"level2_category\", \"value\":  \"Housewares\"},\n",
        "            {\"name\": \"level3_category\", \"value\":  \"Household Batteries\"}\n",
        "        ],\n",
        "    },\n",
        "]\n",
        "\n",
        "inference_response = inference.create_inference_request(model_name, objects_to_be_classified)\n",
        "\n",
        "print()\n",
        "print(\"Inference request processed. Response:\")\n",
        "print()\n",
        "pprint(inference_response)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YF_KzCPRq-0Y"
      },
      "source": [
        "*Note: For trial accounts, you only have a limited number of objects which you can classify.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5D6E3EXq-0Y"
      },
      "source": [
        "You can also try to come up with your own example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYQZDtG-q-0Y"
      },
      "source": [
        "\n",
        "\n",
        "my_own_items = [\n",
        "    {\n",
        "        \"features\": [\n",
        "            {\"name\": \"manufacturer\", \"value\": \"EDIT\"},\n",
        "            {\"name\": \"description\", \"value\": \"EDIT\"},\n",
        "            {\"name\": \"level1_category\", \"value\":  \"EDIT\"},\n",
        "            {\"name\": \"level2_category\", \"value\":  \"EDIT\"},\n",
        "            {\"name\": \"level3_category\", \"value\":  \"EDIT\"}\n",
        "        ],\n",
        "    },\n",
        "]\n",
        "\n",
        "inference_response = inference.create_inference_request(model_name, my_own_items)\n",
        "\n",
        "print()\n",
        "print(\"Inference request processed. Response:\")\n",
        "print()\n",
        "pprint(inference_response)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtQgWbFIq-0Y"
      },
      "source": [
        "You can also classify multiple objects at once. For each object, the `top_n` parameter determines how many predictions are returned."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v256PkgVq-0Z"
      },
      "source": [
        "objects_to_be_classified = [\n",
        "    {\n",
        "        \"objectId\": \"optional-identifier-1\",\n",
        "        \"features\": [\n",
        "            {\"name\": \"manufacturer\", \"value\": \"Duracell\"},\n",
        "            {\"name\": \"description\", \"value\": \"Compatible with select electronic devices; AAA size; DURALOCK Power Preserve technology; 4-pack\"},\n",
        "            {\"name\": \"level1_category\", \"value\":  \"Connected Home & Housewares\"},\n",
        "            {\"name\": \"level2_category\", \"value\":  \"Housewares\"},\n",
        "            {\"name\": \"level3_category\", \"value\":  \"Household Batteries\"}\n",
        "        ],\n",
        "    },\n",
        "    {\n",
        "        \"objectId\": \"optional-identifier-2\",\n",
        "        \"features\": [\n",
        "            {\"name\": \"manufacturer\", \"value\": \"Duracell\"},\n",
        "            {\"name\": \"description\", \"value\": \"Long-lasting energy; DURALOCK Power Preserve\"},\n",
        "            {\"name\": \"level1_category\", \"value\":  \"Connected Home & Housewares\"},\n",
        "            {\"name\": \"level2_category\", \"value\":  \"Housewares\"},\n",
        "            {\"name\": \"level3_category\", \"value\":  \"Household Batteries\"}\n",
        "        ],\n",
        "    },\n",
        "    {\n",
        "        \"objectId\": \"optional-identifier-3\",\n",
        "        \"features\": [\n",
        "            {\"name\": \"manufacturer\", \"value\": \"Energizer\"},\n",
        "            {\"name\": \"description\", \"value\": \"4-pack AA alkaline batteries; battery tester\"},\n",
        "            {\"name\": \"level1_category\", \"value\":  \"Connected Home & Housewares\"},\n",
        "            {\"name\": \"level2_category\", \"value\":  \"Housewares\"},\n",
        "            {\"name\": \"level3_category\", \"value\":  \"Household Batteries\"}\n",
        "        ],\n",
        "    }\n",
        "]\n",
        "\n",
        "\n",
        "inference_response = inference.create_inference_request(model_name, objects_to_be_classified)\n",
        "\n",
        "print()\n",
        "print(\"Inference request processed. Response:\")\n",
        "print()\n",
        "pprint(inference_response)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcJl6sPaq-0Z"
      },
      "source": [
        "To learn how to execute inference calls without the SDK just using the underlying RESTful API, see [Inference without the SDK](#Inference-without-the-SDK)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwCmhddWq-0Z"
      },
      "source": [
        "## Summary Exercise 01.4\n",
        "\n",
        "In exercise 01.4, we have covered the following topics:\n",
        "\n",
        "* How to deploy a previously trained model\n",
        "* How to execute inference requests against a deployed model\n",
        "\n",
        "You can find optional exercises related to exercise 01.4 [below](#Optional-Exercises-for-01.4)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y06aK2IRq-0Z"
      },
      "source": [
        "# Wrapping up\n",
        "\n",
        "In this workshop, we looked into the following topics:\n",
        "\n",
        "* Installation of the Python SDK for Data Attribute Recommendation\n",
        "* Modelling data with a DatasetSchema\n",
        "* Uploading data into a Dataset\n",
        "* Training a model\n",
        "* Predicting labels for unlabelled data\n",
        "\n",
        "Using these tools, we are able to solve the problem of missing Master Data attributes starting from just a CSV file containing training data.\n",
        "\n",
        "Feel free to revisit the workshop materials at any time. The [resources](#Resources) section below contains additional reading.\n",
        "\n",
        "If you would like to explore the additional capabilities of the SDK, visit the [optional exercises](#Optional-Exercises) below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3sXpTFdq-0a"
      },
      "source": [
        "## Cleanup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLrBzgxsq-0a"
      },
      "source": [
        "During the course of the workshop, we have created several resources on the Data Attribute Recommendation Service:\n",
        "\n",
        "* DatasetSchema\n",
        "* Dataset\n",
        "* Job\n",
        "* Model\n",
        "* Deployment\n",
        "\n",
        "The SDK provides several methods to delete these resources. Note that there are dependencies between objects: you cannot delete a Dataset without deleting the Model beforehand.\n",
        "\n",
        "You will need to set `CLEANUP_SESSION = True` below to execute the cleanup."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aa8EDc_Kq-0a"
      },
      "source": [
        "# Clean up all resources created earlier\n",
        "\n",
        "CLEANUP_SESSION = True\n",
        "\n",
        "def cleanup_session():\n",
        "    model_manager.delete_deployment_by_id(deployment_id) # this can take a few seconds\n",
        "    model_manager.delete_model_by_name(model_name)\n",
        "    model_manager.delete_job_by_id(job_id)\n",
        "\n",
        "    data_manager.delete_dataset_by_id(dataset_id)\n",
        "    data_manager.delete_dataset_schema_by_id(dataset_schema_id)\n",
        "    print(\"DONE cleaning up!\")\n",
        "\n",
        "if CLEANUP_SESSION:\n",
        "    print(\"Cleaning up resources generated in this session.\")\n",
        "    cleanup_session()\n",
        "else:\n",
        "    print(\"Not cleaning up. Set 'CLEANUP_SESSION = True' above and run again!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qjmoNE8q-0a"
      },
      "source": [
        "## Resources\n",
        "\n",
        "*Back to [table of contents](#Table-of-Contents)*\n",
        "\n",
        "### SDK Resources\n",
        "\n",
        "* [SDK source code on Github](https://github.com/SAP/data-attribute-recommendation-python-sdk)\n",
        "* [SDK documentation](https://data-attribute-recommendation-python-sdk.readthedocs.io/en/latest/)\n",
        "* [How to obtain support](https://github.com/SAP/data-attribute-recommendation-python-sdk/blob/master/README.md#how-to-obtain-support)\n",
        "* [Tutorials: Classify Data Records with the SDK for Data Attribute Recommendation](https://developers.sap.com/group.cp-aibus-data-attribute-sdk.html)\n",
        "\n",
        "### Data Attribute Recommendation\n",
        "\n",
        "* [SAP Help Portal](https://help.sap.com/viewer/product/Data_Attribute_Recommendation/SHIP/en-US)\n",
        "* [API Reference](https://help.sap.com/viewer/105bcfd88921418e8c29b24a7a402ec3/SHIP/en-US/b45cf9b24fd042d082c16191aa938c8d.html)\n",
        "* [Tutorials using Postman - interact with the service RESTful API directly](https://developers.sap.com/mission.cp-aibus-data-attribute.html)\n",
        "* [Trial Account Limits](https://help.sap.com/viewer/105bcfd88921418e8c29b24a7a402ec3/SHIP/en-US/c03b561eea1744c9b9892b416037b99a.html)\n",
        "* [Metering and Pricing](https://help.sap.com/viewer/105bcfd88921418e8c29b24a7a402ec3/SHIP/en-US/1e093326a2764c298759fcb92c5b0500.html)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksgA4_Axq-0a"
      },
      "source": [
        "## Addendum"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bb2jvwUNq-0b"
      },
      "source": [
        "### Inference without the SDK\n",
        "\n",
        "*Back to [table of contents](#Table-of-Contents)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDCD7OjOq-0d"
      },
      "source": [
        "The Data Attribute Service exposes a RESTful API. The SDK we use in this workshop uses this API to interact with the DAR service.\n",
        "\n",
        "For custom integration, you can implement your own client for the API. The tutorial \"[Use Machine Learning to Classify Data Records]\" is a great way to explore the Data Attribute Recommendation API with the Postman REST client. Beyond the tutorial, the [API Reference] is a comprehensive documentation of the RESTful interface.\n",
        "\n",
        "[Use Machine Learning to Classify Data Records]: https://developers.sap.com/mission.cp-aibus-data-attribute.html\n",
        "\n",
        "[API Reference]: https://help.sap.com/viewer/105bcfd88921418e8c29b24a7a402ec3/SHIP/en-US/b45cf9b24fd042d082c16191aa938c8d.html\n",
        "\n",
        "To demonstrate the underlying API, the next example uses the `curl` command line tool to perform an inference request against the Inference API.\n",
        "\n",
        "The example uses the `jq` command to extract the credentials from the service. The authentication token is retrieved from the `uaa_url` and then used for the inference request."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVRy8Jmrq-0e"
      },
      "source": [
        "# If the following example gives you errors that the jq or curl commands cannot be found,\n",
        "# you may be able to install them from conda by uncommenting one of the lines below:\n",
        "#%conda install -q jq\n",
        "#%conda install -q curl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "LHnJrk4Rq-0f"
      },
      "source": [
        "%%bash -s \"$model_name\" # Pass the python model_name variable as the first argument to shell script\n",
        "\n",
        "model_name=$1\n",
        "\n",
        "echo \"Model: $model_name\"\n",
        "\n",
        "key=$(cat key.json)\n",
        "url=$(echo $key | jq -r .url)\n",
        "uaa_url=$(echo $key | jq -r .uaa.url)\n",
        "clientid=$(echo $key | jq -r .uaa.clientid)\n",
        "clientsecret=$(echo $key | jq -r .uaa.clientsecret)\n",
        "\n",
        "echo \"Service URL: $url\"\n",
        "\n",
        "token_url=${uaa_url}/oauth/token?grant_type=client_credentials\n",
        "\n",
        "echo \"Obtaining token with clientid $clientid from $token_url\"\n",
        "\n",
        "bearer_token=$(curl \\\n",
        "                --silent --show-error \\\n",
        "                --user $clientid:$clientsecret \\\n",
        "                $token_url \\\n",
        "                | jq -r .access_token\n",
        "             )\n",
        "\n",
        "inference_url=${url}/inference/api/v3/models/${model_name}/versions/1\n",
        "\n",
        "echo \"Running inference request against endpoint $inference_url\"\n",
        "\n",
        "echo \"\"\n",
        "\n",
        "# We pass the token in the Authorization header.\n",
        "# The payload for the inference request is passed as\n",
        "# the body of the POST request below.\n",
        "# The output of the curl command is piped through `jq`\n",
        "# for pretty-printing\n",
        "curl \\\n",
        "    --silent --show-error \\\n",
        "    --header \"Authorization: Bearer ${bearer_token}\" \\\n",
        "    --header \"Content-Type: application/json\" \\\n",
        "    -XPOST \\\n",
        "    ${inference_url} \\\n",
        "    -d '{\n",
        "          \"objects\": [\n",
        "            {\n",
        "              \"features\": [\n",
        "                {\n",
        "                  \"name\": \"manufacturer\",\n",
        "                  \"value\": \"Energizer\"\n",
        "                },\n",
        "                {\n",
        "                  \"name\": \"description\",\n",
        "                  \"value\": \"Alkaline batteries; 1.5V\"\n",
        "                },\n",
        "                {\n",
        "                  \"name\": \"price\",\n",
        "                  \"value\": \"5.99\"\n",
        "                }\n",
        "              ]\n",
        "            }\n",
        "          ]\n",
        "        }' | jq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F45MVwAOq-0f"
      },
      "source": [
        "### Cleaning up a service instance\n",
        "\n",
        "*Back to [table of contents](#Table-of-Contents)*\n",
        "\n",
        "To clean all data on the service instance, you can run the following snippet. The code is self-contained and does not require you to execute any of the cells above. However, you will need to have the `key.json` containing a service key in place.\n",
        "\n",
        "You will need to set `CLEANUP_EVERYTHING = True` below to execute the cleanup.\n",
        "\n",
        "**NOTE: This will delete all data on the service instance!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWTgrzVRq-0f"
      },
      "source": [
        "CLEANUP_EVERYTHING = False\n",
        "\n",
        "def cleanup_everything():\n",
        "    import logging\n",
        "    import sys\n",
        "\n",
        "    logging.basicConfig(level=logging.INFO, stream=sys.stdout)\n",
        "\n",
        "    import json\n",
        "    import os\n",
        "\n",
        "    if not os.path.exists(\"key.json\"):\n",
        "        msg = \"key.json is not found. Please follow instructions above to create a service key of\"\n",
        "        msg += \" Data Attribute Recommendation. Then, upload it into the same directory where\"\n",
        "        msg += \" this notebook is saved.\"\n",
        "        print(msg)\n",
        "        raise ValueError(msg)\n",
        "\n",
        "    with open(\"key.json\") as file_handle:\n",
        "        key = file_handle.read()\n",
        "        SERVICE_KEY = json.loads(key)\n",
        "\n",
        "    from sap.aibus.dar.client.model_manager_client import ModelManagerClient\n",
        "\n",
        "    model_manager = ModelManagerClient.construct_from_service_key(SERVICE_KEY)\n",
        "\n",
        "    for deployment in model_manager.read_deployment_collection()[\"deployments\"]:\n",
        "        model_manager.delete_deployment_by_id(deployment[\"id\"])\n",
        "\n",
        "    for model in model_manager.read_model_collection()[\"models\"]:\n",
        "        model_manager.delete_model_by_name(model[\"name\"])\n",
        "\n",
        "    for job in model_manager.read_job_collection()[\"jobs\"]:\n",
        "        model_manager.delete_job_by_id(job[\"id\"])\n",
        "\n",
        "    from sap.aibus.dar.client.data_manager_client import DataManagerClient\n",
        "\n",
        "    data_manager = DataManagerClient.construct_from_service_key(SERVICE_KEY)\n",
        "\n",
        "    for dataset in data_manager.read_dataset_collection()[\"datasets\"]:\n",
        "        data_manager.delete_dataset_by_id(dataset[\"id\"])\n",
        "\n",
        "    for dataset_schema in data_manager.read_dataset_schema_collection()[\"datasetSchemas\"]:\n",
        "        data_manager.delete_dataset_schema_by_id(dataset_schema[\"id\"])\n",
        "        \n",
        "    print(\"Cleanup done!\")\n",
        "\n",
        "if CLEANUP_EVERYTHING:\n",
        "    print(\"Cleaning up all resources in this service instance.\")\n",
        "    cleanup_everything()\n",
        "else:\n",
        "    print(\"Not cleaning up. Set 'CLEANUP_EVERYTHING = True' above and run again.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0k8ONaQq-0g"
      },
      "source": [
        "### Optional Exercises\n",
        "\n",
        "*Back to [table of contents](#Table-of-Contents)*\n",
        "\n",
        "To work with the optional exercises, create a new cell in the Jupyter notebook by clicking the `+` button in the menu above or by using the `b` shortcut on your keyboard. You can then enter your code in the new cell and execute it.\n",
        "\n",
        "#### Optional Exercises for 01.2\n",
        "\n",
        "##### DatasetSchemas\n",
        "\n",
        "Use the [`DataManagerClient.read_dataset_schema_by_id()`](https://data-attribute-recommendation-python-sdk.readthedocs.io/en/latest/api.html#sap.aibus.dar.client.data_manager_client.DataManagerClient.read_dataset_schema_by_id) and the [`DataManagerClient.read_dataset_schema_collection()`](https://data-attribute-recommendation-python-sdk.readthedocs.io/en/latest/api.html#sap.aibus.dar.client.data_manager_client.DataManagerClient.read_dataset_schema_collection) methods to list the newly created and all DatasetSchemas, respectively.\n",
        "\n",
        "##### Datasets\n",
        "\n",
        "Use the [`DataManagerClient.read_dataset_by_id()`](https://data-attribute-recommendation-python-sdk.readthedocs.io/en/latest/api.html#sap.aibus.dar.client.data_manager_client.DataManagerClient.read_dataset_by_id) and the [`DataManagerClient.read_dataset_collection()`](https://data-attribute-recommendation-python-sdk.readthedocs.io/en/latest/api.html#sap.aibus.dar.client.data_manager_client.DataManagerClient.read_dataset_collection) methods to inspect the newly created dataset.\n",
        "\n",
        "Instead of using two separate methods to upload data and wait for validation to finish, you can also use [`DataManagerClient.upload_data_and_validate()`](https://data-attribute-recommendation-python-sdk.readthedocs.io/en/latest/api.html#sap.aibus.dar.client.data_manager_client.DataManagerClient.upload_data_and_validate).\n",
        "\n",
        "#### Optional Exercises for 01.3\n",
        "\n",
        "##### ModelTemplates\n",
        "\n",
        "Use the [`ModelManagerClient.read_model_template_collection()`](https://data-attribute-recommendation-python-sdk.readthedocs.io/en/latest/api.html#sap.aibus.dar.client.model_manager_client.ModelManagerClient.read_model_template_collection) to list all existing model templates.\n",
        "\n",
        "##### Jobs\n",
        "\n",
        "Use [`ModelManagerClient.read_job_by_id()`](https://data-attribute-recommendation-python-sdk.readthedocs.io/en/latest/api.html#sap.aibus.dar.client.model_manager_client.ModelManagerClient.read_job_by_id) and [`ModelManagerClient.read_job_collection()`](https://data-attribute-recommendation-python-sdk.readthedocs.io/en/latest/api.html#sap.aibus.dar.client.model_manager_client.ModelManagerClient.read_job_collection) to inspect the job we just created.\n",
        "\n",
        "The entire process of uploading the data and starting the training is also available as a single method call in [`ModelCreator.create()`](https://data-attribute-recommendation-python-sdk.readthedocs.io/en/latest/api.html#sap.aibus.dar.client.workflow.model.ModelCreator.create).\n",
        "\n",
        "#### Optional Exercises for 01.4\n",
        "\n",
        "##### Deployments\n",
        "\n",
        "Use [`ModelManagerClient.read_deployment_by_id()`](https://data-attribute-recommendation-python-sdk.readthedocs.io/en/latest/api.html#sap.aibus.dar.client.model_manager_client.ModelManagerClient.read_deployment_by_id) and [`ModelManagerClient.read_deployment_collection()`](https://data-attribute-recommendation-python-sdk.readthedocs.io/en/latest/api.html#sap.aibus.dar.client.model_manager_client.ModelManagerClient.read_deployment_collection) to inspect the Deployment.\n",
        "\n",
        "Use the [`ModelManagerclient.lookup_deployment_id_by_model_name()`](https://data-attribute-recommendation-python-sdk.readthedocs.io/en/latest/api.html#sap.aibus.dar.client.model_manager_client.ModelManagerClient.lookup_deployment_id_by_model_name) method to find the deployment ID for a given model name.\n",
        "\n",
        "##### Inference\n",
        "\n",
        "Use the [`InferenceClient.do_bulk_inference()`](https://data-attribute-recommendation-python-sdk.readthedocs.io/en/latest/api.html#sap.aibus.dar.client.inference_client.InferenceClient.do_bulk_inference) method to process more than fifty objects at a time. Note how the data format returned changes."
      ]
    }
  ]
}